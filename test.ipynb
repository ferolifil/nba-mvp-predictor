{
 "cells": [
  {
   "cell_type": "raw",
   "id": "forbidden-luxembourg",
   "metadata": {},
   "source": [
    "cols = ['Player', 'Pos', 'Age','Share'] \n",
    "classifier_nba_dataset = full_nba_dataset.drop(cols,axis=1)\n",
    "\n",
    "nro_corrects_l1 = 0\n",
    "nro_corrects_svc = 0\n",
    "\n",
    "C = 10\n",
    "# kernel = 1.0 * RBF([1.0, 1.0])  # for GPC\n",
    "\n",
    "models = {\n",
    "#     'L1 logistic': LogisticRegression(C=C, penalty='l1',\n",
    "#                                       solver='saga',\n",
    "#                                       multi_class='multinomial',\n",
    "#                                       max_iter=10000),\n",
    "#     'L2 logistic (Multinomial)': LogisticRegression(C=C, penalty='l2',\n",
    "#                                                     solver='saga',\n",
    "#                                                     multi_class='multinomial',\n",
    "#                                                     max_iter=10000),\n",
    "#     'L2 logistic (OvR)': LogisticRegression(C=C, penalty='l2',\n",
    "#                                             solver='saga',\n",
    "#                                             multi_class='ovr',\n",
    "#                                             max_iter=10000),\n",
    "#     'Linear SVC': SVC(),\n",
    "#     'GPC': GaussianProcessClassifier(),\n",
    "#    'K-Neighbors' : KNeighborsClassifier()\n",
    "    'Decision Tree' : DecisionTreeClassifier(criterion='entropy',max_depth=3)\n",
    "}\n",
    "\n",
    "for season in np.arange(1981,2021,1):\n",
    "\n",
    "    print(f'Season : {season}\\n--------------------------------')\n",
    "\n",
    "    y_train = classifier_nba_dataset.loc[(classifier_nba_dataset['Season'] != season),['Status']]\n",
    "    y_train = np.ravel(y_train)\n",
    "    y_test = classifier_nba_dataset.loc[(classifier_nba_dataset['Season'] == season),['Status']]\n",
    "    y_test = np.ravel(y_test)\n",
    "\n",
    "    X_train = classifier_nba_dataset.loc[(classifier_nba_dataset['Season'] != season),:].drop(['Status','Season'], axis=1)\n",
    "    X_test = classifier_nba_dataset.loc[(classifier_nba_dataset['Season'] == season),:].drop(['Status','Season'], axis=1)    \n",
    "\n",
    "    for model_name in models.keys():\n",
    "\n",
    "        models[model_name].fit(X_train, y_train)\n",
    "\n",
    "        pred = models[model_name].predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, pred)\n",
    "        accuracy = '{0:.2f}'.format(accuracy*100)\n",
    "        accuracy = str(accuracy) + '%'\n",
    "        print(model_name + \" : \" + accuracy)\n",
    "\n",
    "        df = full_nba_dataset.loc[(full_nba_dataset['Season'] == season),['Player','Status','Share']]\n",
    "        df['Pred'] = pred.tolist()\n",
    "        df = df.loc[(df['Status'] != 'OOR'),:].sort_values(by='Share', ascending=False)\n",
    "        df = df.drop('Share',axis=1)\n",
    "\n",
    "        if df.iloc[0,1] == df.iloc[0,2]:\n",
    "            print('Success')\n",
    "            if model_name == 'L1 logistic':\n",
    "                nro_corrects_l1 += 1\n",
    "            else:\n",
    "                nro_corrects_svc += 1\n",
    "        else:\n",
    "            print('Fail')\n",
    "\n",
    "        display(df.iloc[:3])\n",
    "\n",
    "print(f'L1_SUCCESS_RATE: {nro_corrects_l1/40}\\nSVC_SUCCESS_RATE: {nro_corrects_svc/40}')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "grateful-partition",
   "metadata": {},
   "source": [
    "cols = ['Player', 'Pos', 'Age','Share'] \n",
    "classifier_nba_dataset = full_nba_dataset.drop(cols,axis=1)\n",
    "\n",
    "C = 10\n",
    "models = {\n",
    "    'L1 logistic': LogisticRegression(C=C, penalty='l1',\n",
    "                                      solver='saga',\n",
    "                                      multi_class='multinomial',\n",
    "                                      max_iter=10000),\n",
    "    'L2 logistic (Multinomial)': LogisticRegression(C=C, penalty='l2',\n",
    "                                                    solver='saga',\n",
    "                                                    multi_class='multinomial',\n",
    "                                                    max_iter=10000),\n",
    "    'L2 logistic (OvR)': LogisticRegression(C=C, penalty='l2',\n",
    "                                            solver='saga',\n",
    "                                            multi_class='ovr',\n",
    "                                            max_iter=10000),\n",
    "    'Linear SVC': SVC(),\n",
    "    'GPC': GaussianProcessClassifier(),    \n",
    "    'K-Neighbors' : KNeighborsClassifier(),\n",
    "    'Decision Tree' : DecisionTreeClassifier(criterion='entropy',max_depth=3)\n",
    "    \n",
    "}\n",
    "\n",
    "y = classifier_nba_dataset['Status']\n",
    "X = classifier_nba_dataset.drop('Status',axis=1)\n",
    "\n",
    "for model_name in models:\n",
    "    scores = cross_val_score(models[model_name], X, y, cv=5)\n",
    "    print(f'{model_name} : {scores.mean()} >> {scores} ')\n",
    "    \n",
    "# Order : L1 = L2 > L2 OvR > SVC > K-Neighbors > GPC \n",
    "# L1 logistic : 0.9621882346560533 >> [0.95753425 0.96484018 0.95981735 0.96757991 0.96116948] \n",
    "# L2 logistic (Multinomial) : 0.9621882346560533 >> [0.95753425 0.96484018 0.95981735 0.96757991 0.96116948] \n",
    "# L2 logistic (OvR) : 0.9618231464503924 >> [0.95616438 0.96392694 0.95981735 0.96575342 0.96345363] \n",
    "# Linear SVC : 0.9545166263029554 >> [0.94794521 0.95981735 0.95159817 0.95616438 0.95705802] \n",
    "# K-Neighbors : 0.9524157524859665 >> [0.9456621  0.956621   0.95251142 0.95479452 0.95248972]\n",
    "# GPC : 0.9395378720084441 >> [0.93926941 0.93926941 0.93972603 0.93972603 0.93969849] "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
